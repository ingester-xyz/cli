{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ingester CLI \ud83d\udeb0","text":"<p>Welcome to Ingester, a CLI tool to easily ingest AWS S3 objects into Walrus storage.</p> <p></p> <p>This site contains everything you need to understand, install, and operate the tool.</p> <p>\ud83d\udc49 Jump to:</p> <ul> <li>What is Ingester?</li> <li>Why Ingester?</li> <li>Technical Guide</li> <li>Examples</li> </ul>"},{"location":"examples/examples/","title":"Ingester CLI examples \ud83d\udeb0","text":""},{"location":"examples/examples/#examples-are-available-here","title":"Examples are available here.","text":"<p>These examples provides a set of scripts for ingesting files into Walrus from an S3 bucket.</p> <ul> <li><code>s3-aws-ingestion.sh</code>: Ingests files from an S3 bucket into Walrus.</li> </ul> <p>Make sure to configure your environment variables (<code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, <code>AWS_REGION</code>, <code>AWS_S3_BUCKET</code>) correctly before running the scripts.</p> <p>The scripts use the <code>ingester</code> Go CLI to perform the ingestion process \ud83d\udeb0.</p>"},{"location":"examples/examples/#folder-structure","title":"Folder Structure","text":"<p>The <code>examples/</code> folder contains the following scripts:</p> <ul> <li><code>s3-aws-ingestion.sh</code>: Ingests files from an S3 bucket into Walrus.</li> <li><code>env</code>: Contains the AWS environment variables required to interact with the S3 bucket.</li> </ul>"},{"location":"examples/examples/#prerequisites","title":"Prerequisites","text":""},{"location":"examples/examples/#1-go-environment","title":"1. Go Environment","text":"<p>Ensure Go is installed and configured on your machine. To check if Go is installed, run:</p> <pre><code>go version\n</code></pre> <p>If Go is not installed, follow the Go installation guide to install Go.</p>"},{"location":"examples/examples/#3-ingest-cli-binary","title":"3. Ingest CLI Binary","text":"<p>The <code>ingester</code> binary must be built using the Go source code before running the ingestion scripts. The <code>s3-aws-ingestion.sh</code> scripts will automatically build the binary.</p>"},{"location":"examples/examples/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"examples/examples/#1-set-environment-variables","title":"1. Set Environment Variables","text":"<p>In the <code>env</code> file located in the <code>examples/</code> folder, you must configure your AWS credentials and the S3 bucket name.</p> <p>Example of the <code>env</code> file:</p> <pre><code>#!/bin/bash\n\n# AWS env variables to provide S3 bucket read+list access\nexport AWS_ACCESS_KEY_ID=\"&lt;your-aws-access-key-id&gt;\"\nexport AWS_SECRET_ACCESS_KEY=\"&lt;your-aws-secret-access-key&gt;\"\nexport AWS_REGION=\"&lt;your-aws-default-region&gt;\"\n\nexport AWS_S3_BUCKET=\"&lt;your-aws-s3-bucket-name-to-ingest-from&gt;\"\n</code></pre> <p>Replace the placeholders (<code>&lt;your-aws-access-key-id&gt;</code>, <code>&lt;your-aws-secret-access-key&gt;</code>, etc.) with your actual AWS credentials and the S3 bucket name.</p>"},{"location":"examples/examples/#running-the-scripts","title":"Running the Scripts","text":""},{"location":"examples/examples/#2-ingesting-files-from-an-s3-bucket","title":"2. Ingesting Files from an S3 Bucket","text":"<p>To ingest files from an S3 bucket into Walrus, run the following script:</p> <pre><code>./examples/s3-aws-ingestion.sh\n</code></pre> <p>This script performs the following:</p> <ol> <li>Sets the necessary environment variables for AWS access.</li> <li>Checks if the required AWS environment variables are set.</li> <li>Verifies that the AWS CLI is installed and configured.</li> <li>Builds the Go <code>ingester</code> binary.</li> <li>Executes the ingestion process using the <code>ingester s3</code> command with the configured S3 bucket and region.</li> </ol>"},{"location":"examples/examples/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any errors while running the scripts, check the following:</p> <ol> <li>AWS Environment Variables: Ensure the AWS environment variables are correctly set in the <code>env</code> file.</li> <li>Permission Issues: Make sure your AWS user has the necessary permissions to access the S3 bucket (<code>s3:ListBucket</code>, <code>s3:GetObject</code>).</li> </ol>"},{"location":"guide/commands/","title":"CLI Commands","text":""},{"location":"guide/commands/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Go (v1.18 or later) installed and on your <code>PATH</code>.</p> </li> <li> <p>AWS credentials (with S3 read access) available via environment variables:</p> </li> </ol> <pre><code>export AWS_ACCESS_KEY_ID=&lt;your-aws-access-key-id&gt;\nexport AWS_SECRET_ACCESS_KEY=&lt;your-aws-secret-access-key&gt;\nexport AWS_REGION=&lt;your-aws-default-region&gt;\n</code></pre> <ol> <li>Walrus endpoints (public gateway URLs) configured in your shell:</li> </ol> <pre><code># Single var for both read/write\nexport WALRUS_ENDPOINT=\"https://aggregator.walrus-testnet.walrus.space,https://publisher.walrus-testnet.walrus.space\"\n\n# Or separate for more control\nexport WALRUS_AGGREGATOR_URLS=\"https://aggregator.walrus-testnet.walrus.space\"\nexport WALRUS_PUBLISHER_URLS=\"https://publisher.walrus-testnet.walrus.space\"\n</code></pre>"},{"location":"guide/commands/#building","title":"Building","text":"<pre><code># Clone the repository\ngit clone git@github.com:ingester-xyz/cli.git\ncd cli\n\n# Download dependencies\ngo mod tidy\n\n# Build the binary\ngo build -o ingester .\n</code></pre> <p>This generates an executable named <code>ingester</code> in your project root.</p>"},{"location":"guide/commands/#commands-overview","title":"Commands Overview","text":"<p>All commands live under the <code>ingester</code> root command:</p> Command Description <code>s3</code> Ingests all objects from a bucket into Walrus and persists refs metadata <code>list</code> Lists all ingested S3 keys from a metadata blob <code>get</code> Retrieves a single file by its S3 key and writes to stdout or file <code>url</code> Get public URL for AWS S3 ingested data key in Walrus"},{"location":"guide/commands/#1-ingester-s3","title":"1. <code>ingester s3</code>","text":"<p>Downloads every object from an S3 bucket, uploads each to Walrus, then writes a single metadata blob containing the S3-to-BlobID map.</p> <pre><code>ingester s3 \\\n  --bucket my-bucket       \\\n  --region us-west-2\n# \u2192 Refs metadata stored as blob: QmSvz\u2026Yz123\n</code></pre> <ul> <li> <p>Flags:</p> </li> <li> <p><code>--bucket</code> (string, required)</p> </li> <li><code>--region</code> (string, required)</li> </ul>"},{"location":"guide/commands/#2-ingester-list","title":"2. <code>ingester list</code>","text":"<p>Prints all original S3 keys stored in the given metadata blob.</p> <pre><code>ingester list --meta-blob-id QmSvz\u2026Yz123\n</code></pre> <ul> <li> <p>Flags:</p> </li> <li> <p><code>--meta-blob-id</code> (string, required)</p> </li> </ul>"},{"location":"guide/commands/#3-ingester-get","title":"3. <code>ingester get</code>","text":"<p>Fetches one ingested file by its original S3 key and writes the raw bytes to stdout or a file.</p> <pre><code># To stdout:\ningester get \\\n  --meta-blob-id QmSvz\u2026Yz123 \\\n  --key path/to/file.txt\n\n# \u2192 Hello, this is the content of file.txt.\n# \u2192 It was originally stored in an AWS S3 bucket\n# \u2192 and ingested into Walrus via the CLI.\n# \u2192 Enjoy your data! \ud83d\udeb0\n</code></pre> <ul> <li> <p>Flags:</p> </li> <li> <p><code>--meta-blob-id</code> (string, required)</p> </li> <li><code>--key</code> (string, required)</li> </ul>"},{"location":"guide/commands/#example-workflow","title":"Example Workflow","text":"<ol> <li>Ingest an S3 bucket into Walrus:</li> </ol> <pre><code>export AWS_ACCESS_KEY=&lt;you-aws-access-key&gt;\nexport AWS_SECRET_ACCESS_KEY=&lt;you-aws-secret-key&gt;\nexport AWS_REGION=&lt;you-aws-region&gt;\nexport WALRUS_ENDPOINT=\"https://aggregator.walrus-testnet.walrus.space,https://publisher.walrus-testnet.walrus.space\"\n\n./ingester s3 --bucket my-test-bucket --region eu-west-1\n# \u2192 Refs metadata stored as blob: QmSvz\u2026Yz123\n</code></pre> <ol> <li>List all ingested keys:</li> </ol> <pre><code>./ingester list --meta-blob-id QmSvz\u2026Yz123\n</code></pre> <ol> <li>Retrieve one file:</li> </ol> <pre><code>./ingester get --meta-blob-id QmSvz\u2026Yz123 --key path/to/file.txt\n</code></pre>"},{"location":"intro/what-is-ingester/","title":"What is Ingester?","text":"<p>Ingester is a Go-based CLI tool that makes ingesting data into Walrus seamless and predictable.</p> <p>Just like opening the tap \ud83d\udeb0</p> <p>In its first iteration, it focuses on migrating existing data from AWS S3 into Walrus. Along the way, it generates a metadata file that enables efficient search operations (e.g., <code>list</code> or <code>get</code>), similar to the native behavior of AWS S3. This simplifies the management of large volumes of blobs stored in Walrus.</p> <p></p> <p>In the future, more integrations are ready to come (e.g. Arweave -&gt; Walrus).</p>"},{"location":"intro/what-is-ingester/#context","title":"Context","text":"<p>Today, Walrus stores data as scattered blobs, with no built-in structure, and ingesting data into it is a manual, fragmented process. As a result, every team has to build their own solution.</p> <p>Ingester solves these two critical pain points by:</p> <ul> <li> <p>Adding an automatic, schema-driven structure that organizes and relates blobs predictably.</p> </li> <li> <p>Providing ready-to-use integrations (like AWS S3) so teams can easily ingest data without extra development effort.</p> </li> </ul> <p>With Ingester, Walrus transforms from a raw storage system into a plug-and-play, developer-friendly platform. Therefore accelerating adoption, reducing barriers, and unlocking its full potential across real-world use cases.</p>"},{"location":"intro/why-ingester/","title":"Why use Ingester?","text":""},{"location":"intro/why-ingester/#the-problem","title":"The Problem","text":"<p>Walrus stores data as unstructured blobs, leaving developers to manually organize and relate them. Today, ingestion is fragmented \u2014 each team builds its own solution. This slows adoption and introduces avoidable technical hurdles.</p>"},{"location":"intro/why-ingester/#the-solution","title":"The Solution","text":"<p>Ingester brings structure and automation to Walrus:</p> <ul> <li> <p>Automatically organizes blobs using a metadata-driven approach</p> </li> <li> <p>Integrates out-of-the-box with sources like AWS S3 (more coming in the future)</p> </li> <li> <p>Enables a plug-and-play developer experience \u2014 no need to reinvent ingestion pipelines</p> </li> </ul>"},{"location":"intro/why-ingester/#value-proposition","title":"Value Proposition","text":"<p>Ingester solves two key challenges for teams using Walrus:</p> <ul> <li> <p>Adds structure: Turns scattered blobs into connected, queryable data by using metadata files after ingestion.</p> </li> <li> <p>Removes friction: Provides ready-made ingestion flows to save time and reduce complexity</p> </li> </ul> <p>With Ingester, Walrus becomes a developer-friendly, ready-to-use storage platform \u2014 accelerating adoption and unlocking the full potential of decentralized storage.</p>"}]}